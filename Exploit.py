import torch
from model import LinearQNet
import agent
from ExcelManipulation import PIDSimulator
from helper import statescale,getAction
from importlib import reload
import random
import pandas as pd
reload(agent)
from agent import Agent


PercentChange = 0.4

def Exploit():
    jitter = []
    maxError = []
    totalError = []
    AbserrorQlist = []
    plist = []
    ilist = []
    dlist = []
    rewardlist = []
    trailErrorList = []

    Exagent = Agent()
    sim = PIDSimulator()
    Exagent.model.load_state_dict(torch.load(".\models\model_672.pth"))  #569,672

       
    
    iter = 0
    sim.SetInitialProcessValues(5,250)   #show 5,250 corner case solved by 569
    input("Initial Values Set. Press key to proceed")
    # p = [0,1000]
    # i = [0, 5000]
    # d  = [0,1]
    # maxscale = [max(maxError),max(totalError),max(maxError)]
    maxState = Exagent.getState(sim)
    minstate = [0,0,0,0,0,1,0]

    
    sp = sim.getProcessValues()
    sim.saveInitialState()

    while True:
        
        state_old = Exagent.getState(sim)
        pid1 = sim.getPID()
        pid2 = pid1.copy()
        
        Final_Move= Exagent.get_action_exploit(state_old,maxState,pid1)

        print("Final Move", Final_Move)

        reward = sim.Simulate(Final_Move)

        state_new = Exagent.getState(sim)

        maxError.append(state_new[0])
        totalError.append(state_new[1])
        jitter.append(state_new[2])
        AbserrorQlist.append(state_new[3])
        trailErrorList.append(state_new[4])
        # plist.append(Final_Move[0])
        # ilist.append(Final_Move[1])
        # dlist.append(Final_Move[2])
        rewardlist.append(reward)

        #maxState = [max(maxError),max(totalError),max(jitter),max(AbserrorQlist),max(trailErrorList),max(plist),max(ilist)]


        maxerror,totalerror,pvjitter,AbserrorQ,trailError,p,i=state_new[0],state_new[1],state_new[2],state_new[3],state_new[4],state_new[5],state_new[6]

        print("P : {0} ; I : {1} ; D : {2} ; MaxError : {3} ; TotalError : {4} ; Jitter : {5} ; ErrorQ75 : {6}  ; reward : {7}".format(Final_Move[0],
        Final_Move[1],Final_Move[2],maxerror,totalerror,pvjitter,AbserrorQ,reward))

        EpisodeFinish = True if  AbserrorQ < 0.0001   else False

        if maxerror>0.5*sp:
            reward -= 100
        
        if AbserrorQ < 0.0001 and pvjitter < 5:
            reward += 100

        
        #state_new = statescale(state_new,maxState)

       

        action = getAction(Final_Move,pid2)

        print("Action : ", action)

        #train Short memory
        #Exagent.train_short_memory(state_old,action,reward,state_new,EpisodeFinish,iter)

        #remember
        #Exagent.remember(state_old,action,reward,state_new,EpisodeFinish)

        
        iter+=1

        if EpisodeFinish:

            input("Tuning done. Press key to proceed for next episode")

            iter = 0
            
            if state_new[2] <= 2:
                print('Jitter suggests trailing error is zero {0}'.format(str(state_old)))

            elif maxerror > 0.5*sp:
                print('maxError high, Episode Ending {0}'.format(str(state_old)))

            if Exagent.n_trials%2 == 0:
                p = random.randint(100,500)
                i = random.randint(100,500)
                d = 0
            
            else:
                p = random.randint(1,10)
                i = random.randint(1,10)
                d = 0
            sim.SetInitialProcessValues(p,i,d)
            
            Exagent.n_trials += 1
            #Exagent.train_long_memory(iter)

            
            
            df = pd.DataFrame(list(zip(maxError,totalError,jitter,AbserrorQlist,plist,ilist,dlist,rewardlist)),columns=['MaxError','TotalError','Jitter','AbserrorQlist','p','i','d','reward'])
            #df = pd.DataFrame(list(zip(**Exagent.memory)))
            
            df.to_csv('Trend')
            input("New Values Set Press key to proceed")

            print("After Episode {0} MaxError is {1} TotalError is {2} PVJitter is {3}".format(Exagent.n_trials,state_new[0],state_new[1],state_new[2]))
            Exagent.model.save(Exagent.n_trials)
            if iter>10000:
                break


if __name__ == '__main__':
    Exploit()